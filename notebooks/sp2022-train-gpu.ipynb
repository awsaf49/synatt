{"cells":[{"cell_type":"markdown","metadata":{},"source":["# [IEEE Signal Processing CUP 2022](https://signalprocessingsociety.org/community-involvement/signal-processing-cup)\n","\n","> Synthetic Speech Attribution\n","\n","<img src=\"https://user-images.githubusercontent.com/36858976/153433391-0c47d037-33c9-4942-aec7-3532b97378d1.jpg\" width=600>"]},{"cell_type":"markdown","metadata":{},"source":["# Get Code\n","* Unzip code folder.\n","* Set `sp2022-tf` as current directory."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# delete existing\n","# !rm -r ../sp2022-tf\n","\n","# change current directory to <code> directory\n","%cd ../sp2022-tf"]},{"cell_type":"markdown","metadata":{},"source":["## Important Notes\n","* All audio files must be in `.wav` format.\n","* Sample Rate must be `16,000`.\n","* For training, `batch_size` is tuned for `8 x V100`. If models is trained in other device, `batch_size` needs to be tuned accordingly using `--batch` argument.\n","* `learning_rate` depends on `batch_size` hence if it `batch_size` is altered then `learning_rate` needs to be tuned accordingly.\n","* Total `epochs` is determined using **Cross-Validation** for provided training data. If **Training** data is changed then Total `epochs` needs to be tuned using **Cross-Validation**, setting `--all-data=0` in [train.py](../train.py).\n","* While training, **Internet** Connection is required to download **ImageNet** weights for CNN Backbones.\n","* To reproduce the result, it is recommended to run code in same **Device Configuration**.\n","* For inference, `batch_size` is tuned for `8 x V100`. For any other device, `batch_size` may need to be modified. To modify `batch_size` change following codes in [predict.py](../predict.py),\n","\n","```py\n","# CONFIGURE BATCHSIZE\n","mx_dim = np.sqrt(np.prod(dim))\n","if mx_dim>=768 or any(i in model_name for i in ['convnext','ECA_NFNetL2']):\n","    CFG.batch_size = CFG.replicas * 16\n","elif mx_dim>=640  or any(i in model_name for i in ['EfficientNet','RegNet','ResNetRS50','ResNest50']):\n","    CFG.batch_size = CFG.replicas * 32\n","else:\n","    CFG.batch_size = CFG.replicas * 64\n","```\n","* Final output will be saved at `output/result`"]},{"cell_type":"markdown","metadata":{},"source":["# Direct Prediction\n","To directly generate prediction on **eval** data without any **Training** using **provided** checkpoints, refer to [sp2022-infer-gpu](sp2022-train-gpu.ipynb) notebook."]},{"cell_type":"markdown","metadata":{},"source":["## 0. Requirements\n","\n","## Hardware\n","* GPU (model or N/A):   8x NVIDIA Tesla V100\n","* Memory (GB):   8 x 32GB\n","* OS: Amazon Linux\n","* CUDA Version : 11.0\n","* Driver Version : 450.119.04\n","* CPU RAM : 128 GiB\n","* DISK : 2 TB\n","\n","\n","Install necessary dependencies using following command,"]},{"cell_type":"markdown","metadata":{},"source":["## Library"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"collapsed":true,"execution":{"iopub.execute_input":"2022-03-31T00:28:08.133968Z","iopub.status.busy":"2022-03-31T00:28:08.133359Z","iopub.status.idle":"2022-03-31T00:28:43.365874Z","shell.execute_reply":"2022-03-31T00:28:43.364971Z","shell.execute_reply.started":"2022-03-31T00:28:08.133927Z"},"id":"B8V1WPsVyv6i","jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["%pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Data Preparation\n","* Step 1: Competition data needs to be in the `./data/` folder. It is mendatory to have the data in exact same format like it was provided.\n","\n","* Step 2: External datasets needs to be downloaded from following links and needs to be in the `./data/` folder,\n","    1. LJSpeech: [link](https://www.kaggle.com/datasets/showmik50/ljspeech-sr16k-dataset) (~2GB)\n","    2. VCTK: [link](https://www.kaggle.com/datasets/showmik50/vctk-sr16k-dataset) (~3GB)\n","    3. LibriSpeech: [link](https://www.kaggle.com/datasets/benimaru069/librispeech-small-dataset) (~15GB)\n","    4. Synthetic: [link](https://www.kaggle.com/datasets/burns070/aps22-synthetic-dataset) (~5GB)\n","\n","> **Note:** All the datasets were pre-processed to have exact same **sample_rate** = `16k` and **file_format** = `.wav`. \n","\n","\n","## Data Path Format\n","Datasets are expected to have following format,\n","\n","```shell\n","├── data\n","│   ├── aps22-synthetic-dataset\n","│   ├── librispeech-small-dataset\n","│   ├── ljspeech-sr16k-dataset\n","│   ├── vctk-sr16k-dataset\n","│   ├── spcup_2022_training_part1\n","│   │   └── spcup_2022_training_part1\n","│   ├── spcup_2022_unseen\n","│   │   └── spcup_2022_unseen\n","│   ├── spcup_2022_eval_part1\n","│   │   └── spcup_2022_eval_part1\n","│   ├── spcup_2022_eval_part2\n","│   │   └── spcup_2022_eval_part2\n","```\n","\n","To use custom directory, `PATHS.json` needs to modified using following cell,"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-31T00:28:43.376507Z","iopub.status.busy":"2022-03-31T00:28:43.376254Z","iopub.status.idle":"2022-03-31T00:28:43.385135Z","shell.execute_reply":"2022-03-31T00:28:43.384389Z","shell.execute_reply.started":"2022-03-31T00:28:43.376474Z"},"trusted":true},"outputs":[],"source":["import json\n","paths = {\n","    \"TRAIN_DATA_DIR\": \"./data/spcup_2022_training_part1/spcup_2022_training_part1/\",\n","    \"UNSEEN_DATA_DIR\": \"./data/spcup_2022_unseen/spcup_2022_unseen/\",\n","    \"TEST1_DATA_DIR\": \"./data/spcup_2022_eval_part1/spcup_2022_eval_part1/\",\n","    \"TEST2_DATA_DIR\": \"./data/spcup_2022_eval_part2/spcup_2022_eval_part2/\",\n","    \"LJ_DATA_DIR\": \"./data/ljspeech-sr16k-dataset/\",\n","    \"VCTK_DATA_DIR\": \"./data/vctk-sr16k-dataset/\",\n","    \"LIBRI_DATA_DIR\": \"./data/librispeech-small-dataset/\",\n","    \"SYNTHETIC_DATA_DIR\": \"./data/aps22-synthetic-dataset/\"\n","}\n","json.dump(paths, open('PATHS.json','w'))\n","\n","# Need this for inference path\n","part1_infer_path = paths['TEST1_DATA_DIR']\n","part2_infer_path = paths['TEST2_DATA_DIR']"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Supervisied Training\n","Competition & external data and their associated labels will be used for **Supervised Training**. All external data is considered as **Unknown Algorithm**.\n","> **Note**: Outputs will be saved at `./output/supervised` folder"]},{"cell_type":"markdown","metadata":{},"source":["## Part-1\n","For Training models for **eval_part1** data run following commands,"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/supervised/part1\\\n","--model=EfficientNetB0\\\n","--batch=64\\\n","--epochs=11"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/supervised/part1\\\n","--model=ResNet50D\\\n","--batch=64\\\n","--epochs=9"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/supervised/part1\\\n","--model=ResNetRS50\\\n","--batch=32\\\n","--epochs=13"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/supervised/part1\\\n","--model=ResNest50\\\n","--batch=32\\\n","--epochs=21"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/supervised/part1\\\n","--model=RegNetZD8\\\n","--batch=64\\\n","--epochs=8"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/supervised/part1\\\n","--model=EfficientNetV2S\\\n","--pretrain=imagenet21k\\\n","--batch=32\\\n","--epochs=25"]},{"cell_type":"markdown","metadata":{},"source":["## Part-2\n","For Training models for **eval_part2** data run following commands,"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=ECA_NFNetL2\\\n","--batch=16\\\n","--epochs=12"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=convnext_base_in22k\\\n","--batch=32\\\n","--epochs=14"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=ResNetRS152\\\n","--batch=32\\\n","--epochs=11"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=convnext_large_in22k\\\n","--batch=16\\\n","--epochs=15"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=RegNetZD8\\\n","--batch=32\\\n","--epochs=5"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=EfficientNetB0\\\n","--batch=64\\\n","--epochs=13"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/supervised/part2\\\n","--model=EfficientNetV2M\\\n","--pretrain=imagenet21k\\\n","--batch=32\\\n","--epochs=15"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Generate Semi-Supervised Labels\n","Run following command to generate **Semi-Supervisied** lables for both **eval_part1&** & **eval_part2** data. \n","> **Note**: Semi-Supervised labels will be saved at `output/supervised/pseudo/pred.csv`."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python generate_pseudo.py\\\n","--part1-model-dir=output/supervised/part1\\\n","--part1-infer-path=$part1_infer_path\\\n","--part2-model-dir=output/supervised/part2\\\n","--part2-infer-path=$part2_infer_path\\\n","--output=output/supervised/pseudo/pred.csv"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Semi-Supervised Training\n","In this stage Competition & External data will be used along with **eval_part1** & **eval_part2** data. For **eval_data** their **semi-supervised** labels will be used which were generated in previous stage. \n","> **Note**: Outputs will be saved at `./output/semi-supervised` folder\n"]},{"cell_type":"markdown","metadata":{},"source":["## Part-1\n","For Training models for **eval_part1** data run following commands,"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/semi-supervised/part1\\\n","--model=EfficientNetB0\\\n","--batch=64\\\n","--epochs=15\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/semi-supervised/part1\\\n","--model=ResNet50D\\\n","--batch=64\\\n","--epochs=18\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/semi-supervised/part1\\\n","--model=ResNetRS50\\\n","--batch=32\\\n","--epochs=17\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/semi-supervised/part1\\\n","--model=ResNest50\\\n","--batch=32\\\n","--epochs=16\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/semi-supervised/part1\\\n","--model=RegNetZD8\\\n","--batch=64\\\n","--epochs=12\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--output-dir=output/semi-supervised/part1\\\n","--model=EfficientNetV2S\\\n","--pretrain=imagenet21k\\\n","--batch=64\\\n","--epochs=7\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"markdown","metadata":{},"source":["## Part-2\n","For Training models for **eval_part2** data run following commands,"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=ECA_NFNetL2\\\n","--batch=16\\\n","--epochs=11\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=convnext_base_in22k\\\n","--batch=16\\\n","--epochs=6\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=ResNetRS152\\\n","--batch=32\\\n","--epochs=16\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=convnext_large_in22k\\\n","--batch=16\\\n","--epochs=10\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=EfficientNetB0\\\n","--batch=32\\\n","--epochs=10\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=EfficientNetB0\\\n","--batch=32\\\n","--epochs=10\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 train.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--output-dir=output/semi-supervised/part2\\\n","--model=EfficientNetV2M\\\n","--pretrain=imagenet21k\\\n","--batch=32\\\n","--epochs=25\\\n","--pseudo 1\\\n","--pseudo_csv=output/supervised/pseudo/pred.csv"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Prediction with **Trained** Models\n","For predicting on **eval_data** using newly trained models use following codes,\n","> **Note**: Outputs will be saved at `output/result`\n"]},{"cell_type":"markdown","metadata":{},"source":["## Part-1\n","To generate prediction for **eval_part1** data using **newly-trained** checkpoints run following commands,"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python predict.py\\\n","--cfg ./configs/sp22-part1.yaml\\\n","--model-dir=output/semi-supervised/part1\\\n","--infer-path=$part1_infer_path\\\n","--output=output/result/pred_part1.csv"]},{"cell_type":"markdown","metadata":{},"source":["## Part-2\n","To generate prediction for **eval_part2** data using **newly-trained** checkpoints run following commands,"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python predict.py\\\n","--cfg ./configs/sp22-part2.yaml\\\n","--model-dir=output/semi-supervised/part2\\\n","--infer-path=$part2_infer_path\\\n","--output=output/result/pred_part2.csv"]},{"cell_type":"markdown","metadata":{},"source":["# Output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!tree"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2022-03-31T01:06:30.354162Z","iopub.status.busy":"2022-03-31T01:06:30.353762Z","iopub.status.idle":"2022-03-31T01:06:31.032722Z","shell.execute_reply":"2022-03-31T01:06:31.031949Z","shell.execute_reply.started":"2022-03-31T01:06:30.354129Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!tree outputs"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
